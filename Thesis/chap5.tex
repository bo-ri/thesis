\chapter{おわりに}
本章では検証実験の結果からモデルの精度について考察する．
また改善点について述べる．

% \section{考察}
% 検証実験ではWord2Vecで生成したモデルと，GloVeで生成したモデルについて検証結果をまとめた．
% 本節ではそれぞれのモデルの検証結果を元に最適なモデルについて考察する．

% \subsection{Word2Vecのモデル}
% それぞれの

% \subsection{GloVeのモデル}

\section{Word2Vecモデルの考察}
3つの出力結果それぞれの観点からモデルの精度を考察する．

\subsection{青山学院大学に近い大学}
最も妥当性が高いと考えられるモデルはWV\_ F \ref{table:wvf}である．
このモデルは単語ベクトルの次元数が100次元，反復回数が10，windowサイズが1000で生成されたモデルである．
このモデルの青山学院大学に近い大学の出力結果には，明治大学，法政大学，立教大学，中央大学が含まれており，同じ偏差値帯からMARCHと分類されている大学が全て得られた．
また，同じミッション系である明治学院大学や，ミッション系かつ偏差値が近い上智大学などの大学も得られた．

次に妥当性が高いと考えられるモデルは，WV\_ H \ref{table:wvh}である．
このモデルは単語ベクトルの次元数が100次元，反復回数が100，windowサイズが1000で生成されたモデルである．
このモデルの青山学院大学に近い大学の出力結果は，明治大学，立教大学，中央大学が含まれている．
WV\_ Fと異なる点は，同志社大学と関西学院大学のような地理的に離れた大学が結果に出てきた点が挙げられる．
これらの大学は青山学院大学と同じミッション系大学で偏差値も近いが，立地が離れているため次点とした．

これらの結果から，青山学院大学に近い大学の出力に関しては，windowサイズは1000で反復回数は10で十分であると考えられる．

\subsection{$ 青山学院大学 - キリスト教 $}
このタスクにおいて最も妥当性が高いと考えられるモデルは，WV\_ E \ref{table:wve}である．
このモデルは単語ベクトルの次元数が50次元，反復回数が10，windowサイズが1000で生成されたモデルである．
出力結果には，明治大学，法政大学，中央大学が含まれており，MARCHと分類されている大学からミッション系の青山学院大学と立教大学が除かれた結果となった．
また青山学院大学に近い大学の出力結果から，明治学院大学，上智大学，立教大学が除かれており，各大学からキリスト教という単語の減算が機能していると考えられる．


次に妥当性が高いと考えられるモデルはWV\_ F \ref{table:wvf}である．
このモデルは単語ベクトルの次元数が100次元，反復回数が10，windowサイズが1000で生成されたモデルである．
もっとも妥当性が高いと考えたWV\_ Eと異なる点は，名古屋大学，大阪大学が出力された点である．
これらの大学は立地的に離れいるが，一方WV\_ Eに出現した横浜市立大学は立地的にも近く，偏差値帯も近いため，WV\_ Fの方が妥当性が低いと考えた．

これらの結果から，このタスクにおいては2つのモデルの差は小さいが，windowサイズは1000が妥当で，反復回数は10で十分であると考えられる．

\subsection{青山学院大学と明治学院大学で共通の近い単語}
このタスクにおいて最も妥当性が高いと考えられるモデルは，WV\_ D \ref{table:wvd}である．
このモデルは単語ベクトルの次元数が100次元，反復回数が100，windowサイズが10で生成されたモデルである．
出力結果は，キリスト，キリスト教，礼拝，宗教，教会，チャペルといったミッション系の大学を連想する単語と，定期という過去に18年間開催された定期戦を連想させる単語と，神学という歴史的背景を連想させる単語が出力された．

次に妥当性が高いと考えられるモデルはWV\_ F \ref{table:wvf}である．
このモデルは単語ベクトルの次元数が100次元，反復回数が10，windowサイズが1000で生成されたモデルである．
このモデルの出力からは，キリスト教，キリスト，教会というミッション系を連想させる単語と，神学，商業，統合といった歴史的背景を連想させるような単語が出現した．

また，WV\_ B \ref{table: wvb}とWV\_ H \ref{table:wvh}もWV\_ F \ref{table: wvf}と同様に，全体に占める関連性のある単語の出現頻度で同じ結果であった．
これらの結果から，このタスクにおいて重要な点は，単語ベクトルの次元数を大きくする点であると考えられる．

\section{GloVeモデルの考察}
GloVeで生成したモデルで出力した3つの結果それぞれの観点からモデルの精度を考察する．

\subsection{青山学院大学と近い大学}
このタスクにおいて最も妥当性が高いと考えられるモデルは，GV\_ C \ref{table:gvc}である．
出力結果から，立教大学，中央大学，明治大学，法政大学が取得できた．
また，ミッション系の大学で上智大学，偏差値が近いと考えられる東京理科大学や成蹊大学，学習院大学が得られた．

GV\_A \ref{table:gva}とGV\_ B \ref{table:gvb}，GV\_ D \ref{table:gvd}も出力結果に大きな差はなかった．
これらの結果から，モデルのwindowサイズは10が妥当であることが分かる．
おそらくwindowサイズを1000に設定すると，学習が収束する前に終わってしまうため，適切な関係性を学習しきれなかったと考えられる．

\subsection{$ 青山学院大学 - キリスト教 $}
このタスクにおいて最も妥当性が高いと考えられるモデルは，WV\_ D \ref{table:gvd}である．
理由としてはまず出力結果にミッション系の大学が含まれていない点が第1に挙げられる．
第2に中央大学，法政大学，明治大学が高い類似度で示されている点が挙げられる．

このほかではGV\_ C \ref{table:gvc}が挙げられるが，上智大学と立教大学が出力されている点でキリスト教の減算がうまく機能していないと考えられる．
これは単語ベクトルのサイズの違いが影響していると考えられるが，これらの結果から，単語ベクトルのサイズは100次元が妥当であり，windowサイズは10で十分であると言える．

\subsection{青山学院大学と明治学院大学で共通の近い単語}
GloVeで生成したモデルでは，windowサイズが小さい場合，このタスクの結果が得られなかった．
最も妥当性の高いと考えられるモデルはGV\_H \ref{table:gvh}である．
出力から，聖書，チャペル，キリスト，キリスト教などのミッション系の大学を連想させる単語と，統合や定期などの歴史的背景を連想させる単語が得られた．
他のモデルでは十分な出力を得られなかったため，このモデルが今回の検証実験で最も妥当性が高いと言える．

\section{モデル評価のまとめ}
Word2Vecで生成したモデルに関しては，総合的に評価して，WV\_ F \ref{table:wvf}が精度が高いと言えた．

またGloVeで生成したモデルに関しては，適切なモデルがタスクによって異なった．
青山学院大学に近い大学を出力するタスクと， $ 青山学院大学 - キリスト教 $ のタスクでは，GV\_ D \ref{table: gvd}が総合的に評価して妥当性が高かった．
青山学院大学と明治学院大学で共通の近い単語を出力するタスクでは，よりwindwoサイズが大きなGV\_ H \ref{table:gvh}の精度が高く，windowサイズを小さくすると結果が得られなかった．

Word2Vecで生成したモデルと，GloVeで生成したモデルを比較すると，全てのタスクに対して安定した出力が期待できるモデルは，Word2Vecで生成したモデルであった．
しかし青山学院大学に近い大学を出力するタスクと， $ 青山学院大学 - キリスト教 $ のタスクではGloVeで生成したモデルの出力の方が，偏差値，ミッション系，立地の観点から妥当性の高い結果となった．

\section{改善点}
まずデータセットに偏りがあることが改善点として挙げられる．
今回使用したデータは，Wikipedia，パスナビ，大学プレスセンターの記事をマージしたものであるが，大学プレスセンターの記事がデータセットにおけるほとんどの割合を占めている．
そこで大学プレスセンターの記事に偏りがあると，モデルの精度に影響が出る．
さらに記事の数も大学によって差があるため，安定したデータセットを収集する必要がある．

また暗黙知のように我々が知っている情報がインターネットから取得できない点も挙げられる．
例えば大学によっておしゃれな印象であったり，お金持ちが多い大学などといった情報は収集するのが難しい．
このような情報はTwitterや5ちゃんねるなどから取得できるかもしれないが，ノイズが非常に多いことが予想される．
それゆえ，様々な媒体から横断的に大量のデータを収集する必要がある．