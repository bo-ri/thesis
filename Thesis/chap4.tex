\chapter{検証実験}
% モデルの精度がどの程度妥当かを検証するために，本章ではパラメータを微調整したモデルの出力結果をまとめる．
% またそれぞれの出力結果に関して評価する．
本研究の核となる部分はモデル部であり，その精度がシステムそのものの完成度を左右する．
したがって，本研究ではモデルの学習時のパラメータと精度の検証実験をおこなった．
本章では，この検証実験の目的，方法，結果および考察について述べる．

\section{実験目的}
Word2VecとGloVeで単語ベクトルのモデルを生成する場合，いくつかのパラメータを考慮する必要がある．
本実験では実際にシステムにモデルを組み込んで，機能を提供する際に最もパフォーマンスの高いモデルを適用するため，いくつかのタスクに分けてモデルを評価する．
% 1つはWord2Vecで生成したモデルで，もう一方はGloVeで生成したモデルである．
% また，それぞれの方法でモデルを生成する際に，異なるパラメータを適用していくつかのモデルを学習した．
適用したパラメータの詳細は次節で説明する．

% 出力した内容は，モデルに対して大学名を入力とし，入力された大学に近い大学名を出力とした．
% また，入力と出力の2つの大学間において近さを定義する共通の単語について，それぞれの大学からの距離を示した．
% 例として，A大学に近い大学としてB大学が得られた場合，A大学とB大学で共通して近い単語を探す．
% 得られた単語からのそれぞれの大学間の距離が近ければ，それぞれの大学が近い要因としての単語を得ることができる．

検証のためにモデルを用いて出力する内容は，青山学院大学に近い大学名， $ 青山学院大学 - キリスト教 $ に該当する大学名，青山学院大学と明治学院大学それぞれで共通する意味が近い単語の3項目とした．
ここで特に2項目の「$ 青山学院大学 - キリスト教 $」におけるマイナスはベクトルの演算を意味し，青山学院大学を構成する要素からキリスト教を構成する要素を引くことを意味する．
また3項目の「青山学院大学と明治学院大学それぞれで共通する意味が近い単語」とは，青山学院大学に近い大学として明治学院大学が得られた場合，青山学院大学と明治学院大学で共通して近い単語を探す．
得られた単語からのそれぞれの大学間の距離が近ければ，それぞれの大学が近い要因としての単語を得ることができる．
青山学院大学の比較対象に明治学院大学を選んだ理由は，同じミッション系の大学で神学部の統合を通した日本神学校の創立などの歴史的な関係性を持っているためである．

\section{実験方法}
モデルを評価する際に，それぞれの出力に対して評価軸を定めた．

青山学院大学に近い大学に関する評価項目は，教育内容，学部構成，ミッション系の大学であること，を総合的に評価する．
% 本研究で参考にした偏差値とキャンパスの立地はパスナビ\cite{passNavi}を参考とした．
% モデルに学部，学科の情報は考慮されていないため，キャンパスの近さは学部を考慮しない．

次に，$ 青山学院大学 - キリスト教 $ の評価項目は，非ミッション系の大学であること，教育内容，学部構成を総合的に評価する．
この場合，大学の要素からはキリスト教が消えていることが期待されるため，非ミッション系の大学であることをもっとも重要な評価項目とする．

最後に，青山学院大学と明治学院大学で共通の近い単語の評価項目は，直接的な関係性を示す単語とした．
これは，両校がミッション系であることから，キリスト教に関する単語などがあげられる．
また，歴史的な背景から日本神学校(現 東京神学大学)の創設に両校の神学部が統合したことから，神学部に関する単語も考慮する．
さらに専門部の統合から商業学部という単語と，1970年から1987年まで行われた体育会の総合定期戦に関連する単語も挙げられる．

\begin{table}[htbp]
\caption{各出力結果の評価軸}
\centering
\begin{tabular}{|l|l|l|}
\hline
青山学院大学に近い大学 & $ 青山学院大学 - キリスト教 $ & 青山学院大学と明治学院大学で共通の近い単語
\\ \hline \hline
教育内容& 教育内容 & 直接的な関係性を示す単語 \\
ミッション系& 非ミッション系 & \\
学部構成 & 学部国政 & \\ \hline
\end{tabular}
\label{table:eval}
\end{table}

% \section{パラメータの詳細}
% 各パラメータの詳細について解説する．

\subsection{単語ベクトルの次元数}
Word2VecとGloVeで指定するパラメータの1つであるベクトルの次元数は，小さすぎると単語の特徴を効率的に学習できず，大きすぎると適切な分散表現が学習できない．
一般的に，50 〜 300次元を指定する．
本研究で使用したデータセットは比較的サイズが小さいため，単語ベクトルの次元数は50次元と100次元で比較した．

\subsection{反復回数}
Word2VecとGloVeの学習の反復回数を指定する．
この数字の大きさに比例して学習に要する時間も大きくなる．
また，反復回数が少なすぎると十分に単語の特徴を学習できないため，検証実験では 10 および 100 のパラメータで比較する．

\subsection{windowサイズ}
windowサイズは10と1000で比較した．
一般的にはwindowサイズは，10 〜 20で学習するが，記事の中に出現する大学名の単語ベクトルを学習する際，対象となる単語は記事全体に出現すると考えられるためwindowサイズに1000を適用して比較する．

\subsection{x-max}
GloVeの学習を行う際に，共起頻度の閾値を指定する必要がある．
Jeffrey Penningtonらの実験では，100,000,000 ~ 600,000,000個のトークンが含まれたコーパスを用いて，x-maxオプションに100を指定した．
一方本論文で学習したデータは約2,400,000個のトークンが含まれたデータを用いたため，x-maxオプションに指定する値は10とした．


\input{word2vecResult}

\input{evaluateWord2Vec}

\input{gloveResult}

\input{evaluateGloVe}

\section{モデル評価のまとめ}
Word2Vecで生成したモデルに関しては，総合的に評価して，WV\_ F 表 \ref{table:wvf}が精度が高いと言えた．

またGloVeで生成したモデルに関しては，適切なモデルがタスクによって異なった．
青山学院大学に近い大学を出力するタスクと， $ 青山学院大学 - キリスト教 $ のタスクでは，GV\_ D 表 \ref{table: gvd}が総合的に評価して妥当性が高かった．
青山学院大学と明治学院大学で共通の近い単語を出力するタスクでは，よりwindwoサイズが大きなGV\_ H 表 \ref{table:gvh}の精度が高く，windowサイズを小さくすると結果が得られなかった．

Word2Vecで生成したモデルと，GloVeで生成したモデルを比較すると，全てのタスクに対して安定した出力が期待できるモデルは，Word2Vecで生成したモデルであった．
しかし青山学院大学に近い大学を出力するタスクと， $ 青山学院大学 - キリスト教 $ のタスクではGloVeで生成したモデルの出力の方が，偏差値，ミッション系，立地の観点から妥当性の高い結果となった．
