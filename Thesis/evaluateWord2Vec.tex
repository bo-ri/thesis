\section{Word2Vecモデルの考察}
3つの出力結果それぞれの観点からモデルの精度を考察する．

\subsection{青山学院大学に近い大学}
最も妥当性が高いと考えられるモデルは，WV\_ H (表 \ref{table:wvh})である．
このモデルは単語ベクトルの次元数が100次元，反復回数が100，windowサイズが1000で生成されたモデルである．
このモデルの青山学院大学に近い大学の出力結果は，明治大学，立教大学，中央大学が含まれている．
また，東京外国語大学は国際系の学部が青山学院大学に近いと考えた．

次に妥当性が高いと考えられるモデルは，WV\_ F (表 \ref{table:wvf})である．
このモデルは単語ベクトルの次元数が100次元，反復回数が10，windowサイズが1000で生成されたモデルである．
このモデルの青山学院大学に近い大学の出力結果には，明治大学，法政大学，立教大学，中央大学が含まれており，同じ偏差値帯からMARCHと分類されている大学が全て得られた．

% 最も妥当性が高いと考えられるモデルはWV\_ F 表 \ref{table:wvf}である．
% このモデルは単語ベクトルの次元数が100次元，反復回数が10，windowサイズが1000で生成されたモデルである．
% % このモデルの青山学院大学に近い大学の出力結果には，明治大学，法政大学，立教大学，中央大学が含まれており，同じ偏差値帯からMARCHと分類されている大学が全て得られた．
% 同じ総合大学である明治大学，法政大学，立教大学，中央大学が含まれており，同じ偏差値帯からMARCHと分類されている大学が全て得られた．
% また，同じミッション系である明治学院大学や，上智大学などの大学も得られた．

% 次に妥当性が高いと考えられるモデルは，WV\_ H 表 \ref{table:wvh}である．
% このモデルは単語ベクトルの次元数が100次元，反復回数が100，windowサイズが1000で生成されたモデルである．
% このモデルの青山学院大学に近い大学の出力結果は，明治大学，立教大学，中央大学が含まれている．
% % WV\_ Fと異なる点は，同志社大学と関西学院大学のような地理的に離れた大学が結果に出てきた点が挙げられる．
% % これらの大学は青山学院大学と同じミッション系大学で偏差値も近いが，立地が離れているため次点とした．


これらの結果から，青山学院大学に近い大学の出力に関しては，windowサイズは1000で反復回数は10で十分であると考えられる．

\subsection{$ 青山学院大学 - キリスト教 $}
このタスクにおいて最も妥当性が高いと考えられるモデルは，WV\_ F (表 \ref{table:wvf})である．
このモデルは単語ベクトルの次元数が100次元，反復回数が10，windowサイズが1000で生成されたモデルである．
キリスト教の減算が機能しているため，青山学院大学に近い単語だけでは確認できなかった仏教系の大学である，駒澤大学や立命館大学が確認できた．

次に妥当性が高いと考えられるモデルはWV\_ E (表 \ref{table:wve})である．
このモデルは単語ベクトルの次元数が50次元，反復回数が10，windowサイズが1000で生成されたモデルである．
出力結果には，明治大学，法政大学，中央大学が含まれており，MARCHと分類されている大学からミッション系の青山学院大学と立教大学が除かれた結果となった．
% もっとも妥当性が高いと考えたWV\_ Eと異なる点は，名古屋大学，大阪大学が出力された点である．
% これらの大学は立地的に離れいるが，一方WV\_ Eに出現した横浜市立大学は立地的にも近く，偏差値帯も近いため，WV\_ Fの方が妥当性が低いと考えた．

これらの結果から，このタスクにおいては2つのモデルの差は小さいが，windowサイズは1000が妥当で，反復回数は10で十分であると考えられる．

\subsection{青山学院大学と明治学院大学で共通の近い単語}
このタスクにおいて最も妥当性が高いと考えられるモデルは，WV\_ D (表 \ref{table:wvd})である．
このモデルは単語ベクトルの次元数が100次元，反復回数が100，windowサイズが10で生成されたモデルである．
出力結果は，キリスト，キリスト教，礼拝，宗教，教会，チャペルといったミッション系の大学を連想する単語と，定期という過去に18年間開催された定期戦を連想させる単語と，神学という歴史的背景を連想させる単語が出力された．

次に妥当性が高いと考えられるモデルはWV\_ F (表 \ref{table:wvf})である．
このモデルは単語ベクトルの次元数が100次元，反復回数が10，windowサイズが1000で生成されたモデルである．
このモデルの出力からは，キリスト教，キリスト，教会というミッション系を連想させる単語と，神学，商業，統合といった歴史的背景を連想させるような単語が出現した．

また，WV\_ B (表 \ref{table:wvb})とWV\_ H (表 \ref{table:wvh})もWV\_ F (表 \ref{table:wvf})と同様に，全体に占める関連性のある単語の出現頻度で同じ結果であった．
これらの結果から，このタスクにおいて重要な点は，単語ベクトルの次元数を大きくする点であると考えられる．

